<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="author" content="Chang">


    <script src="jquery-1.8.3.min.js"></script>
    <script src="../build/vis.js"></script>
    <script src="../build/util.js"></script>
    <script src="../build/convnet.js"></script>
    <script src="../demo/mnist_labels.js"></script>

    <script>

        var layer_defs = new Array();
        var net = new Array();
        var hatched_defs = new Array();
        var hatchedNet = new Array();
        var trainer = new Array();
        var t = new Array();

        //I will take care of the training of mother network later. For now, just the building process.
        var mother_defs, motherNet;
        mother_defs = [];
        mother_defs.push({ type: 'input', out_sx: 28, out_sy: 28, out_depth: 1 });//the mother net needs an input layer by default



        //there are already three children networks by default
        t[0] = "layer_defs[0] = [];\n\
        layer_defs[0].push({type:'input', out_sx:28, out_sy:28, out_depth:1});\n\
        layer_defs[0].push({type:'fc', num_neurons:50, activation:'tanh'});\n\
        layer_defs[0].push({type:'fc', num_neurons:50, activation:'tanh'});\n\
        layer_defs[0].push({type:'fc', num_neurons:50, activation:'tanh'});\n\
        layer_defs[0].push({type:'fc', num_neurons:50, activation:'tanh'});\n\
        layer_defs[0].push({type:'fc', num_neurons:50, activation:'tanh'});\n\
        layer_defs[0].push({type:'softmax', num_classes:10});\n\
        \n\
        net[0] = new convnetjs.Net();\n\
        net[0].makeLayers(layer_defs[0]);\n\
        \n\
        trainer[0] = new convnetjs.SGDTrainer(net[0], {method:'adadelta', batch_size:20, l2_decay:0.001});\n\
        ";

        t[1] = "layer_defs[1] = [];\n\
        layer_defs[1].push({type:'input', out_sx:28, out_sy:28, out_depth:1});\n\
        layer_defs[1].push({type:'fc', num_neurons:550, activation:'tanh'});\n\
        layer_defs[1].push({type:'fc', num_neurons:540, activation:'tanh'});\n\
        layer_defs[1].push({type:'fc', num_neurons:550, activation:'tanh'});\n\
        layer_defs[1].push({type:'fc', num_neurons:540, activation:'tanh'});\n\
        layer_defs[1].push({type:'fc', num_neurons:550, activation:'tanh'});\n\
        layer_defs[1].push({type:'softmax', num_classes:10});\n\
        \n\
        net[1] = new convnetjs.Net();\n\
        net[1].makeLayers(layer_defs[1]);\n\
        \n\
        trainer[1] = new convnetjs.SGDTrainer(net[1], {method:'adadelta', batch_size:20, l2_decay:0.001});\n\
        ";

        t[2] = "layer_defs[2] = [];\n\
        layer_defs[2].push({type:'input', out_sx:28, out_sy:28, out_depth:1});\n\
        layer_defs[2].push({type:'fc', num_neurons:60, activation:'tanh'});\n\
        layer_defs[2].push({type:'fc', num_neurons:50, activation:'tanh'});\n\
        layer_defs[2].push({type:'fc', num_neurons:60, activation:'tanh'});\n\
        layer_defs[2].push({type:'fc', num_neurons:60, activation:'tanh'});\n\
        layer_defs[2].push({type:'fc', num_neurons:60, activation:'tanh'});\n\
        layer_defs[2].push({type:'softmax', num_classes:10});\n\
        \n\
        net[2] = new convnetjs.Net();\n\
        net[2].makeLayers(layer_defs[2]);\n\
        \n\
        trainer[2] = new convnetjs.SGDTrainer(net[2], {method:'adadelta', batch_size:20, l2_decay:0.001});\n\
        ";

        var step_num = 0;
        var maxmin = cnnutil.maxmin;
        var f2t = cnnutil.f2t;
        // ------------------------
        // BEGIN MNIST SPECIFIC STUFF
        // ------------------------
        var classes_txt = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'];

        var use_validation_data = true;

        var num_batches = 21; // 20 training batches, 1 test batch
        var num_bg_batches = 21;
        var test_batch = 20;
        var data_img_elts = new Array(num_batches);
        var bg_data_img_elts = new Array(num_bg_batches);
        var img_data = new Array(num_batches);
        var bg_img_data = new Array(num_bg_batches);
        var loaded = new Array(num_batches);
        var loaded_train_batches = [];

        var sample_training_instance = function () {
            // find an unloaded batch
            var bi = Math.floor(Math.random() * loaded_train_batches.length);
            var b = loaded_train_batches[bi];
            var k = Math.floor(Math.random() * 3000); // sample within the batch
            var n = b * 3000 + k;

            // load more batches over time
            if (step_num % 5000 === 0 && step_num > 0) {
                for (var i = 0; i < num_batches; i++) {
                    if (!loaded[i]) {
                        load_data_batch(i);
                        break;
                    }
                }
            }

            // fetch the appropriate row of the training image and reshape into a Vol
            var p = img_data[b].data;
            var x = new convnetjs.Vol(28, 28, 1, 0.0);
            var W = 28 * 28;
            var j = 0;
            for (var i = 0; i < W; i++) {
                var ix = ((W * k) + i) * 4;
                x.w[i] = p[ix] / 255.0;
            }

            var isval = use_validation_data && n % 10 === 0 ? true : false;
            return { x: x, label: labels[n], isval: isval };
        }

        var sample_bg_training_instance = function () {
            var bg = 0;
            var bi = Math.floor(Math.random() * loaded_train_batches.length);
            var b = loaded_train_batches[bi];
            var k = Math.floor(Math.random() * 3000);
            var n = b * 3000 + k;
            // load more batches over time
            if (step_num % 5000 === 0 && step_num > 0) {
                bg = Math.floor(Math.random() * num_batches);
                load_bg_data_batch(bg);
            }

            // fetch the appropriate row of the training image and reshape into a Vol
            var p = bg_img_data[bg].data;
            var x = new convnetjs.Vol(28, 28, 1, 0.0);
            var W = 28 * 28;
            var j = 0;
            for (var i = 0; i < W; i++) {
                var ix = ((W * k) + i) * 4;
                x.w[i] = p[ix] / 255.0;
            }

            var isval = use_validation_data && n % 10 === 0 ? true : false;
            return { x: x, label: labels[n], isval: isval };
        }

        // // sample a random testing instance
        // var sample_test_instance = function () {

        //     var b = test_batch;
        //     var k = Math.floor(Math.random() * 1000);
        //     var n = b * 1000 + k;

        //     var p = img_data[b].data;
        //     var x = new convnetjs.Vol(32, 32, 3, 0.0);
        //     var W = 32 * 32;
        //     var j = 0;
        //     for (var dc = 0; dc < 3; dc++) {
        //         var i = 0;
        //         for (var xc = 0; xc < 32; xc++) {
        //             for (var yc = 0; yc < 32; yc++) {
        //                 var ix = ((W * k) + i) * 4 + dc;
        //                 x.set(yc, xc, dc, p[ix] / 255.0 - 0.5);
        //                 i++;
        //             }
        //         }
        //     }

        //     // distort position and maybe flip
        //     var xs = [];
        //     //xs.push(x, 32, 0, 0, false); // push an un-augmented copy
        //     for (var k = 0; k < 6; k++) {
        //         var dx = Math.floor(Math.random() * 5 - 2);
        //         var dy = Math.floor(Math.random() * 5 - 2);
        //         xs.push(convnetjs.augment(x, 32, dx, dy, k > 2));
        //     }

        //     // return multiple augmentations, and we will average the network over them
        //     // to increase performance
        //     return { x: xs, label: labels[n] };
        // }

        // int main
        $(window).load(function () {

            for (var i = 0; i < t.length; i++) {
                $("#newnet" + i).val(t[i]);
                eval($("#newnet" + i).val());
                hatched_defs[i] = [];
                hatched_defs[i] = layer_defs[i];
                hatchedNet[i] = new convnetjs.Net();
                hatchedNet[i].makeLayers(hatched_defs[i]);
                trainer[i + 6] = new convnetjs.SGDTrainer(hatchedNet[i], { method: 'adadelta', batch_size: 20, l2_decay: 0.001 });
            }


            //we built mother network here based on layer definitions of each child network
            //we look at all the children networks at all convolutional layers (so we skip Input, pooling and softmax layers)
            //, and add the one with fewest filters into the mother network.
            //find the longest childnet who have the most layers
            var longestLength = 0;
            for (var n = 0; n < layer_defs.length; n++) {
                if (longestLength < layer_defs[n].length) {
                    longestLength = layer_defs[n].length;
                }
            }
            //loop for all positions but skip the input layer and softmax layer.
            for (var i = 1; i < longestLength - 1; i++) {
                var temp_neuronNum = 10000;//hope it's big enough
                //loop for each network
                for (var j = 0; net[j]; j++) {
                    if (layer_defs[j][i].type === 'fc' && layer_defs[j][i].num_neurons < temp_neuronNum && layer_defs[j][i].num_neurons > 0) {
                        temp_neuronNum = layer_defs[j][i].num_neurons;
                    }
                }
                mother_defs.push({ type: 'fc', num_neurons: temp_neuronNum, activation: 'tanh' });
            }
            mother_defs.push({ type: 'softmax', num_classes: 10 });
            motherNet = new convnetjs.Net();
            motherNet.makeLayers(mother_defs);//implement it
            trainer[5] = new convnetjs.SGDTrainer(motherNet, { method: 'adadelta', batch_size: 20, l2_decay: 0.001 });

            //for now, we show the motherNet by simply print each layer
            var m2t = document.getElementById("MotherNet_vis");
            m2t.innerHTML = '';
            for (var i = 0; mother_defs[i]; i++) {
                if (i == 0) {
                    var mt = 'Input layer:' + 'out_sx:' + mother_defs[0].out_sx + ' out_sy:' + mother_defs[0].out_sy + ' out_depth:' + mother_defs[0].out_depth;
                    m2t.appendChild(document.createTextNode(mt));
                    m2t.appendChild(document.createElement('br'));
                }
                else if (mother_defs[i].type === 'fc') {
                    var mt = 'Fully connected layer:' + ' num_neurons:' + mother_defs[i].num_neurons + ' activation:' + mother_defs[i].activation;
                    m2t.appendChild(document.createTextNode(mt));
                    m2t.appendChild(document.createElement('br'));
                }
                else if (i == mother_defs.length - 1) {
                    var mt = 'Softmax layer: number of classes: 10';//since we are using MNIST
                    m2t.appendChild(document.createTextNode(mt));
                }
            }


            for (var k = 0; k < loaded.length; k++) { loaded[k] = false; }

            load_data_batch(0); // async load train set batch 0 (6 total train batches)
            load_data_batch(test_batch); // async load test set (batch 6)
            load_bg_data_batch(0);
            load_bg_data_batch(test_batch);
            start_fun();
            //bg_start_fun();
        });

        var start_fun = function () {
            if (loaded[0] && loaded[test_batch]) {
                console.log('starting!');
                setInterval(load_and_step, 50);
            }
            else { setTimeout(start_fun, 200); } // keep checking
            setInterval(widenNets(motherNet,hatchedNet), 1000); //use Mother Network to update hatched networks every 1 sec
        }
/*
        //hatched part
        var bg_start_fun = function () {
            if (loaded[test_batch]) {
                console.log('BG starting!');
                setInterval(bg_load_and_step, 100);
            }
            else { setTimeout(bg_start_fun, 200); }
        }
*/
        var load_data_batch = function (batch_num) {
            // Load the dataset with JS in background
            data_img_elts[batch_num] = new Image();
            var data_img_elt = data_img_elts[batch_num];
            data_img_elt.onload = function () {
                var data_canvas = document.createElement('canvas');
                data_canvas.width = data_img_elt.width;
                data_canvas.height = data_img_elt.height;
                var data_ctx = data_canvas.getContext("2d");
                data_ctx.drawImage(data_img_elt, 0, 0); // copy it over... bit wasteful :(
                img_data[batch_num] = data_ctx.getImageData(0, 0, data_canvas.width, data_canvas.height);
                loaded[batch_num] = true;
                if (batch_num < 20) { loaded_train_batches.push(batch_num); }
                console.log('finished loading data batch ' + batch_num);
            };
            data_img_elt.src = "mnist_batch_" + batch_num + ".png";
        }

        var load_bg_data_batch = function (batch_num) {
            // Load the dataset with JS in background
            bg_data_img_elts[batch_num] = new Image();
            var bg_data_img_elt = bg_data_img_elts[batch_num];
            bg_data_img_elt.onload = function () {
                var bg_data_canvas = document.createElement('canvas');
                bg_data_canvas.width = bg_data_img_elt.width;
                bg_data_canvas.height = bg_data_img_elt.height;
                var bg_data_ctx = bg_data_canvas.getContext("2d");
                bg_data_ctx.drawImage(bg_data_img_elt, 0, 0); // copy it over... bit wasteful :(
                bg_img_data[batch_num] = bg_data_ctx.getImageData(0, 0, bg_data_canvas.width, bg_data_canvas.height);
                console.log('finished loading bagging data batch ' + batch_num);
            };
            bg_data_img_elt.src = "mnist_batch_" + batch_num + ".png";
        }


        // ------------------------
        // END MNIST SPECIFIC STUFF
        // ------------------------

        // loads a training image and trains on it with the Children Networks and Mother Network
        var paused = false;
        var embed_samples = [];
        var embed_imgs = [];
        var load_and_step = function () {
            if (paused) return;

            if (embed_samples.length === 0) { // happens once
                for (var k = 0; k < 200; k++) {
                    var s = sample_training_instance();
                    embed_samples.push(s);
                    // render x and save it too
                    var I = render_act(s.x);
                    embed_imgs.push(I);
                }
            }
            var sample = sample_training_instance();
            step(sample); // process this image
        }
        // the hatchedNet part
        var embed_bg_samples = [];
        var embed_bg_imgs = [];
        var bg_load_and_step = function () {
            if (paused) return;

            if (embed_bg_samples.length === 0) {
                for (var k = 0; k < 200; k++) {
                    var s = sample_bg_training_instance();
                    embed_bg_samples.push(s);
                    var I = render_act(s.x);
                    embed_bg_imgs.push(I);
                }
            }
            var sample = sample_bg_training_instance();
            bg_step(sample);
        }

        var xLossWindow = new Array();
        var wLossWindow = new Array();
        var trainAccWindow = new Array();
        var valAccWindow = new Array();
        var testAccWindow = new Array();
        for (var i = 0; i < 5; i++) {
            xLossWindow[i] = new cnnutil.Window(100);
            wLossWindow[i] = new cnnutil.Window(100);
            trainAccWindow[i] = new cnnutil.Window(100);
            valAccWindow[i] = new cnnutil.Window(100);
            testAccWindow[i] = new cnnutil.Window(100);
        }
        //the MN part
        xLossWindow[5] = new cnnutil.Window(100);
        wLossWindow[5] = new cnnutil.Window(100);
        trainAccWindow[5] = new cnnutil.Window(100);
        valAccWindow[5] = new cnnutil.Window(100);
        testAccWindow[5] = new cnnutil.Window(100);
        //temp hatchedNet part
        for (var i = 6; i < 10; i++) {
            xLossWindow[i] = new cnnutil.Window(100);
            wLossWindow[i] = new cnnutil.Window(100);
            trainAccWindow[i] = new cnnutil.Window(100);
            valAccWindow[i] = new cnnutil.Window(100);
            testAccWindow[i] = new cnnutil.Window(100);
        }
        //the HatchedNet part
        var bg_xLossWindow = new Array();
        var bg_wLossWindow = new Array();
        var bg_trainAccWindow = new Array();
        var bg_valAccWindow = new Array();
        var bg_testAccWindow = new Array();
        for (var i = 0; i < 5; i++) {
            bg_xLossWindow[i] = new cnnutil.Window(100);
            bg_wLossWindow[i] = new cnnutil.Window(100);
            bg_trainAccWindow[i] = new cnnutil.Window(100);
            bg_valAccWindow[i] = new cnnutil.Window(100);
            bg_testAccWindow[i] = new cnnutil.Window(100);
        }


        var step = function (sample) {
            var x = sample.x;
            var y = sample.label;
            var stats = new Array();
            var lossx = new Array();
            var lossw = new Array();


            if (sample.isval) {
                var yhat = new Array();
                var val_acc = new Array();
                // use x to build our estimate of validation error
                for (var i = 0; net[i]; i++) {
                    net[i].forward(x);
                    yhat[i] = net[i].getPrediction();
                    val_acc[i] = yhat[i] === y ? 1.0 : 0.0;
                    valAccWindow[i].add(val_acc[i]);
                }
                //the MN part
                motherNet.forward(x);
                yhat[5] = motherNet.getPrediction();
                val_acc[5] = yhat[5] === y ? 1.0 : 0.0;
                valAccWindow[5].add(val_acc[5]);
                //temp hatchedNet part
                for (var i = 0; hatchedNet[i]; i++) {
                    hatchedNet[i].forward(x);
                    yhat[i + 6] = hatchedNet[i].getPrediction();
                    val_acc[i + 6] = yhat[i + 6] === y ? 1.0 : 0.0;
                    valAccWindow[i + 6].add(val_acc[i + 6]);
                }
                return;
            }

            // train on it with networks
            for (var i = 0; net[i]; i++) {
                stats[i] = trainer[i].train(x, y);
                lossx[i] = stats[i].cost_loss;
                lossw[i] = stats[i].l2_decay_loss;
                xLossWindow[i].add(lossx[i]);
                wLossWindow[i].add(lossw[i]);
            }
            //the MN part
            stats[5] = trainer[5].train(x, y);
            lossx[5] = stats[5].cost_loss;
            lossw[5] = stats[5].l2_decay_loss;
            xLossWindow[5].add(lossx[5]);
            wLossWindow[5].add(lossw[5]);
            //temp hatchedNet part
            for (var i = 0; hatchedNet[i]; i++) {
                stats[i + 6] = trainer[i + 6].train(x, y);
                lossx[i + 6] = stats[i + 6].cost_loss;
                lossw[i + 6] = stats[i + 6].l2_decay_loss;
                xLossWindow[i + 6].add(lossx[i + 6]);
                wLossWindow[i + 6].add(lossw[i + 6]);
            }


            // keep track of stats such as the average training error and loss
            var yhat = new Array();
            var train_acc = new Array();
            for (var i = 0; net[i]; i++) {
                yhat[i] = net[i].getPrediction();
                train_acc[i] = yhat[i] === y ? 1.0 : 0.0;
                trainAccWindow[i].add(train_acc[i]);
            }
            //the MN part
            yhat[5] = motherNet.getPrediction();
            train_acc[5] = yhat[5] === y ? 1.0 : 0.0;
            trainAccWindow[5].add(train_acc[5]);
            //temp hatchedNet part
            for (var i = 0; hatchedNet[i]; i++) {
                yhat[i+6] = hatchedNet[i].getPrediction();
                train_acc[i+6] = yhat[i+6] === y ? 1.0 : 0.0;
                trainAccWindow[i+6].add(train_acc[i+6]);
            }


            // visualize training status
            var train_elt = document.getElementById("trainstats");
            train_elt.innerHTML = '';
            for (var i = 0; net[i]; i++) {
                var T = 'Forward time of network' + i + ' per example: ' + stats[i].fwd_time + 'ms';
                train_elt.appendChild(document.createTextNode(T));
                train_elt.appendChild(document.createElement('br'));
            }
            var T = 'Forward time of MotherNetwork per example: ' + stats[5].fwd_time + 'ms';
            train_elt.appendChild(document.createTextNode(T));
            train_elt.appendChild(document.createElement('br'));
            for (var i=0; hatchedNet[i]; i++){
                var T = 'Forward time of hatched network' + i + ' per example: ' + stats[i+6].fwd_time + 'ms';
                train_elt.appendChild(document.createTextNode(T));
                train_elt.appendChild(document.createElement('br'));
            }
            for (var i = 0; net[i]; i++) {
                var T = 'Backprop time of network' + i + ' per example: ' + stats[i].bwd_time + 'ms';
                train_elt.appendChild(document.createTextNode(T));
                train_elt.appendChild(document.createElement('br'));
            }
            var T = 'Backprop time of MotherNetwork per example: ' + stats[5].bwd_time + 'ms';
            train_elt.appendChild(document.createTextNode(T));
            train_elt.appendChild(document.createElement('br'));
            for(var i=0;hatchedNet[i];i++){
                var T = 'Backprop time of hatched network' + i + ' per example: ' + stats[i+6].bwd_time + 'ms';
                train_elt.appendChild(document.createTextNode(T));
                train_elt.appendChild(document.createElement('br'));
            }
            for (var i = 0; net[i]; i++) {
                var T = 'Classification loss of network' + i + ' : ' + f2t(xLossWindow[i].get_average());
                train_elt.appendChild(document.createTextNode(T));
                train_elt.appendChild(document.createElement('br'));
            }
            var T = 'Classification loss of MotherNetwork: ' + f2t(xLossWindow[5].get_average());
            train_elt.appendChild(document.createTextNode(T));
            train_elt.appendChild(document.createElement('br'));
            for(var i = 0; hatchedNet[i];i++){
                var T = 'Classification loss of hatched network' + i + ' : ' + f2t(xLossWindow[i+6].get_average());
                train_elt.appendChild(document.createTextNode(T));
                train_elt.appendChild(document.createElement('br'));
            }
            for (var i = 0; net[i]; i++) {
                var T = 'L2 Weight decay loss of network' + i + ' : ' + f2t(wLossWindow[i].get_average());
                train_elt.appendChild(document.createTextNode(T));
                train_elt.appendChild(document.createElement('br'));
            }
            var T = 'L2 Weight decay loss of MotherNetwork: ' + f2t(wLossWindow[5].get_average());
            train_elt.appendChild(document.createTextNode(T));
            train_elt.appendChild(document.createElement('br'));
            for(var i =0;hatchedNet[i];i++){
                var T = 'L2 Weight decay loss of hatched network' + i + ' : ' + f2t(wLossWindow[i+6].get_average());
                train_elt.appendChild(document.createTextNode(T));
                train_elt.appendChild(document.createElement('br'));
            }
            for (var i = 0; net[i]; i++) {
                var T = 'Training accuracy of network' + i + ' : ' + f2t(trainAccWindow[i].get_average());
                train_elt.appendChild(document.createTextNode(T));
                train_elt.appendChild(document.createElement('br'));
            }
            var T = 'Training accuracy of MotherNetwork: ' + f2t(trainAccWindow[5].get_average());
            train_elt.appendChild(document.createTextNode(T));
            train_elt.appendChild(document.createElement('br'));
            for(var i=0;hatchedNet[i];i++){
                var T = 'Training accuracy of hatched network' + i + ' : ' + f2t(trainAccWindow[i+6].get_average());
                train_elt.appendChild(document.createTextNode(T));
                train_elt.appendChild(document.createElement('br'));
            }
            for (var i = 0; net[i]; i++) {
                var T = 'Validation accuracy of network' + i + ' : ' + f2t(valAccWindow[i].get_average());
                train_elt.appendChild(document.createTextNode(T));
                train_elt.appendChild(document.createElement('br'));
            }
            var T = 'Validation accuracy of MotherNetwork: ' + f2t(valAccWindow[5].get_average());
            train_elt.appendChild(document.createTextNode(T));
            train_elt.appendChild(document.createElement('br'));
            for(var i=0;hatchedNet[i];i++){
                var T = 'Validation accuracy of hatched network' + i + ' : ' + f2t(valAccWindow[i+6].get_average());
                train_elt.appendChild(document.createTextNode(T));
                train_elt.appendChild(document.createElement('br'));
            }
            var T = 'Examples seen: ' + step_num;
            train_elt.appendChild(document.createTextNode(T));
            train_elt.appendChild(document.createElement('br'));

            step_num++;
        }

/*
        var bg_step = function (sample) {
            var x = sample.x;
            var y = sample.label;
            var stats = new Array();
            var lossx = new Array();
            var lossw = new Array();


            if (sample.isval) {
                var yhat = new Array();
                var val_acc = new Array();
                // use x to build our estimate of validation error
                for (var i = 0; hatchedNet[i]; i++) {
                    hatchedNet[i].forward(x);
                    yhat[i] = hatchedNet[i].getPrediction();
                    val_acc[i] = yhat[i] === y ? 1.0 : 0.0;
                    bg_valAccWindow[i].add(val_acc[i]);
                }
                return;
            }

            // train on it with networks
            for (var i = 0; hatchedNet[i]; i++) {
                stats[i] = trainer[i + 6].train(x, y);
                lossx[i] = stats[i].cost_loss;
                lossw[i] = stats[i].l2_decay_loss;
                bg_xLossWindow[i].add(lossx[i]);
                bg_wLossWindow[i].add(lossw[i]);
            }

            // keep track of stats such as the average training error and loss
            var yhat = new Array();
            var train_acc = new Array();
            for (var i = 0; hatchedNet[i]; i++) {
                yhat[i] = hatchedNet[i].getPrediction();
                train_acc[i] = yhat[i] === y ? 1.0 : 0.0;
                bg_trainAccWindow[i].add(train_acc[i]);
            }


            // visualize training status
            var train_elt = document.getElementById("HatchedNets_trainstats");
            train_elt.innerHTML = '';
            for (var i = 0; hatchedNet[i]; i++) {
                var T = 'Forward time of hatched network' + i + ' per example: ' + stats[i].fwd_time + 'ms';
                train_elt.appendChild(document.createTextNode(T));
                train_elt.appendChild(document.createElement('br'));
            }
            for (var i = 0; hatchedNet[i]; i++) {
                var T = 'Backprop time of hatched network' + i + ' per example: ' + stats[i].bwd_time + 'ms';
                train_elt.appendChild(document.createTextNode(T));
                train_elt.appendChild(document.createElement('br'));
            }
            for (var i = 0; hatchedNet[i]; i++) {
                var T = 'Classification loss of hatched network' + i + ' : ' + f2t(bg_xLossWindow[i].get_average());
                train_elt.appendChild(document.createTextNode(T));
                train_elt.appendChild(document.createElement('br'));
            }
            for (var i = 0; hatchedNet[i]; i++) {
                var T = 'L2 Weight decay loss of hatched network' + i + ' : ' + f2t(bg_wLossWindow[i].get_average());
                train_elt.appendChild(document.createTextNode(T));
                train_elt.appendChild(document.createElement('br'));
            }
            for (var i = 0; hatchedNet[i]; i++) {
                var T = 'Training accuracy of hatched network' + i + ' : ' + f2t(bg_trainAccWindow[i].get_average());
                train_elt.appendChild(document.createTextNode(T));
                train_elt.appendChild(document.createElement('br'));
            }
            for (var i = 0; hatchedNet[i]; i++) {
                var T = 'Validation accuracy of hatched network' + i + ' : ' + f2t(bg_valAccWindow[i].get_average());
                train_elt.appendChild(document.createTextNode(T));
                train_elt.appendChild(document.createElement('br'));
            }

        }
*/

        //build the hatched networks
        function randomFrom(lowerValue, upperValue) {
                return Math.floor(Math.random() * (upperValue - lowerValue) + lowerValue);
            }
        function widenNets(motherNet,hatchedNet){
            //For the original part in MN, just copy them
            for (var l = 1; l < motherNet.layers.length; l++) { //loop by each layer in MN
                if (motherNet.layers[l].layer_type === 'fc') {
                    console.log(l);
                    for (var f = 0; f < motherNet.layers[l].filters.length; f++) { //loop by each "filter" in a certain fc layer
                        for (var i = 0; i < motherNet.layers[l].filters[f].w.length; i++) { //loop by each weight in a certain "filter"
                            for (var j = 0; hatchedNet[j]; j++) { //copy the weight to every hatchedNet
                                hatchedNet[j].layers[l].filters[f].w[i] = motherNet.layers[l].filters[f].w[i];
                            }
                        }
                    }
                }
            }
            //For the widened part, use the random select
            for (var h = 0; hatchedNet[h]; h++) { //build each hatchedNet one by one
                for (var l = 1; l < motherNet.layers.length; l++) { //loop by each layer in MN except for the last one
                    if (motherNet.layers[l].layer_type === 'fc') {
                        var rdmSlct = 0;
                        var copyCount = new Array(motherNet.layers[l].filters.length), i = copyCount.length; //count how many times has a filter in a certain layer of MN been copied
                        while (i--) { copyCount[i] = 0; } //initialize them with 0
                        var copyPosition = new Array(motherNet.layers[l].filters.length); //log the position in hatchedNet which copied the a certain filter of MN
                        for (var j = 0; j < copyPosition.length; j++) { //initialize them with 0
                            copyPosition[j] = new Array(hatchedNet[h].layers[l].filters.length - motherNet.layers[l].filters.length);
                            for (var k = 0; k < copyPosition[j].length; k++) {
                                copyPosition[j][k] = 0;
                            }
                        }
                        for (var f = motherNet.layers[l].filters.length; f < hatchedNet[h].layers[l].filters.length; f++) { //build the widened part in a certain layer
                            rdmSlct = randomFrom(0, motherNet.layers[l].filters.length); //randomly select a filter in the layer l of MN
                            //console.log(copyPosition[rdmSlct][f - motherNet.layers[l].filters.length]+','+rdmSlct+','+(f - motherNet.layers[l].filters.length));
                            hatchedNet[h].layers[l].filters[f] = motherNet.layers[l].filters[rdmSlct]; //copy it to the filter f in the widened part of layer l in hatchedNet
                            copyCount[rdmSlct]++; //log the copyCount
                            copyPosition[rdmSlct][f - motherNet.layers[l].filters.length] = 1; //log the copy position
                        }
                        if (motherNet.layers[l + 2].layer_type === 'fc') {
                            for (var nxt = 0; nxt < motherNet.layers[l + 2].filters.length; nxt++) { //deal with the next layer
                                for (var f = 0; f < motherNet.layers[l].filters.length; f++) { //for the copied filter f in layer l, we divide the counter part, weight f in every filter of layer l+1 of MN original part, by copyCount+1
                                    if (copyCount[f] > 0) {
                                        hatchedNet[h].layers[l + 2].filters[nxt].w[f] /= (copyCount[f] + 1);
                                        for (var i = motherNet.layers[l].filters.length; i < hatchedNet[h].layers[l].filters.length; i++) { //for the filters in widened part who copied the filter f in MN, we use the updated filter in MN original part to update them
                                            if (copyPosition[f][i - motherNet.layers[l].filters.length] === 1) {
                                                hatchedNet[h].layers[l + 2].filters[i] = hatchedNet[h].layers[l + 2].filters[nxt];
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }


        var reset_all = function () {
            // reinit trainer
            trainer = new Array();
            for (var i = 0; net[i]; i++) {
                trainer[i] = new convnetjs.SGDTrainer(net[i], { method: 'adadelta', batch_size: 4, l2_decay: 0.0001 });
            }

            // reinit windows that keep track of val/train accuracies
            for (var i = 0; $("#newnet" + i).val(); i++) {
                xLossWindow[i].reset();
                wLossWindow[i].reset();
                trainAccWindow[i].reset();
                valAccWindow[i].reset();
                testAccWindow[i].reset();
            }

            step_num = 0;


        }

        var change_net = function () {
            layer_defs = [];
            net = [];
            for (var i = 0; $("#newnet" + i).val(); i++) {
                eval($("#newnet" + i).val());

            }
            reset_all();


            //I'm lazy now, so just paste the code above :(
            var longestLength = 0;
            for (var n = 0; n < layer_defs.length; n++) {
                if (longestLength < layer_defs[n].length) {
                    longestLength = layer_defs[n].length;
                }
            }
            //loop for all positions but skip the input layer and softmax layer.
            for (var i = 1; i < longestLength - 1; i++) {
                var temp_neuronNum = 10000;//hope it's big enough
                //loop for each network
                for (var j = 0; net[j]; j++) {
                    if (layer_defs[j][i].type === 'fc' && layer_defs[j][i].num_neurons < temp_neuronNum && layer_defs[j][i].num_neurons > 0) {
                        temp_neuronNum = layer_defs[j][i].num_neurons;
                    }
                }
                mother_defs.push({ type: 'fc', num_neurons: temp_neuronNum, activation: 'tanh' });
            }
            mother_defs.push({ type: 'softmax', num_classes: 10 });
            motherNet = new convnetjs.Net();
            motherNet.makeLayers(mother_defs);//implement it

            //for now, we show the motherNet by simply print each layer
            var m2t = document.getElementById("MotherNet_vis");
            m2t.innerHTML = '';
            for (var i = 0; mother_defs[i]; i++) {
                if (i == 0) {
                    var mt = 'Input layer:' + 'out_sx:' + mother_defs[0].out_sx + ' out_sy:' + mother_defs[0].out_sy + ' out_depth:' + mother_defs[0].out_depth;
                    m2t.appendChild(document.createTextNode(mt));
                    m2t.appendChild(document.createElement('br'));
                }
                else if (mother_defs[i].type === 'fc') {
                    var mt = 'Fully connected layer:' + ' num_neurons:' + mother_defs[i].num_neurons + ' activation:' + mother_defs[i].activation;
                    m2t.appendChild(document.createTextNode(mt));
                    m2t.appendChild(document.createElement('br'));
                }
                else if (i == mother_defs.length - 1) {
                    var mt = 'Softmax layer: number of classes: 10';//since we are using MNIST
                    m2t.appendChild(document.createTextNode(mt));
                }
            }


        }


    </script>
</head>




<body>

    <div id="wrap">

        <h1>Train Stats</h1>
        <div id="trainstats"></div>


        <h1>Instantiate Networks and Trainers</h1>
        <div>
            <!--for now, we allow a user to specify up to 5 children networks-->
            <textarea id="newnet0" style="width:70%; height:200px;"></textarea>
            <br />
            <textarea id="newnet1" style="width:70%; height:200px;"></textarea>
            <br />
            <textarea id="newnet2" style="width:70%; height:200px;"></textarea>
            <br />
            <textarea id="newnet3" style="width:70%; height:200px;"></textarea>
            <br />
            <textarea id="newnet4" style="width:70%; height:200px;"></textarea>
            <br />
            <input id="buttonnn" type="submit" value="change network" onclick="change_net();" style="width:200px;height:30px;" />
        </div>

        <div>
            <h1>Generated MotherNet</h1>
            <div id="MotherNet_vis"></div>
        </div>
        <h1>Train Stats of Hatched Nets</h1>
        <div id="HatchedNets_trainstats"></div>

    </div>

</body>



</html>